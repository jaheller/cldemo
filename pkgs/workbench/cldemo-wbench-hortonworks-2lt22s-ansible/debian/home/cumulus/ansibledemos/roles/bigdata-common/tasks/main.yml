- name: add -hadoop entries to /etc/hosts for hadoop binding interface
  lineinfile: dest=/etc/hosts regexp='.*{{ item }}-hadoop$' line="{{server_interfaces[item][hadoop.interface]["address"]}} {{item}}-hadoop" state=present
  when: server_interfaces[item][hadoop.interface]["address"] is defined
  with_items: groups['bigdata_servers']

- name: configure server /etc/network/interfaces
  template: src=server-interfaces.j2 dest=/etc/network/interfaces
  notify: restart server networking

- name: install python-pycurl
  apt: pkg=python-pycurl state=latest

- name: add hortonworks key
  apt_key: url=http://keyserver.ubuntu.com/pks/lookup?op=get&fingerprint=on&search=0xB9733A7A07513CAD state=present

- name: add hortonworks repo
  apt_repository: repo='deb http://public-repo-1.hortonworks.com/HDP/ubuntu12/2.1.5.0 HDP main' state=present

- name: add hortonworks utils repo
  apt_repository: repo='deb http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.19/repos/ubuntu12 HDP-UTILS main' state=present

- name: install hadoop pkgs
  apt: name={{item}} update_cache=yes
  with_items:
  - hadoop
  - hadoop-client
  - hadoop-hdfs
  - hadoop-mapreduce
  - hadoop-yarn
  - libhdfs0
  - libhdfs0-dev
  - ntp
  - openssl
  - openjdk-7-jre

- name: create a path for java /usr/java
  file: state=directory path=/usr/java/

- name: create a symlink for java into /usr/java/default
  file: src=/usr/lib/jvm/java-7-openjdk-amd64/jre state=link path=/usr/java/default

- name: clean out default hadoop config /etc/hadoop/conf/*
  shell: /bin/rm /etc/hadoop/conf/*
  args:
    removes: /etc/hadoop/conf/slaves

- name: configure server /etc/hadoop/conf/*
  template: src=server-{{item}}.j2 dest=/etc/hadoop/conf/{{item}} mode=755
  with_items:
    - capacity-scheduler.xml
    - commons-logging.properties
    - container-executor.cfg
    - core-site.xml
    - createDirs.sh
    - directories.sh
    - hadoop-env.sh
    - hadoop-metrics2.properties-GANGLIA
    - hadoop-metrics2.properties
    - hadoop-policy.xml
    - hdfs-site.xml
    - health_check
    - log4j.properties
    - mapred-queue-acls.xml
    - mapred-site.xml
    - usersAndGroups.sh
    - yarn-env.sh
    - yarn-site.xml

- name: add hadoop environments scripts to bash.bashrc
  lineinfile: dest=/etc/bash.bashrc line="{{item}}"
  with_items:
    - "if [ -f /etc/hadoop/conf/directories.sh ]; then"
    - ". /etc/hadoop/conf/directories.sh"
    - "fi;"
    - "if [ -f /etc/hadoop/conf/usersAndGroups.sh ]; then"
    - ". /etc/hadoop/conf/usersAndGroups.sh"
    - "fi ;"

- name: create hadoop data directories
  command: /bin/bash createDirs.sh
  args:
    chdir: /etc/hadoop/conf 

- name: create init scripts
  template: src=server-init-script.j2 
            dest=/etc/init.d/{{item.serviceclass}}-{{item.service}}
            mode=755
  with_items:
  - { serviceclass: hadoop, service: namenode, user: hdfs }
  - { serviceclass: hadoop, service: datanode, user: hdfs }
  - { serviceclass: yarn, service: resourcemanager, user: yarn }
  - { serviceclass: yarn, service: nodemanager, user: yarn }
  - { serviceclass: mapred, service: historyserver, user: mapred }

- name: create client user
  user: name={{hadoop.client_user}} groups=users
